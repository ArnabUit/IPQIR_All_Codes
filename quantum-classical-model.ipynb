{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94a98f8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:10:19.013405Z",
     "iopub.status.busy": "2025-10-15T17:10:19.012971Z",
     "iopub.status.idle": "2025-10-15T17:10:22.698043Z",
     "shell.execute_reply": "2025-10-15T17:10:22.696988Z"
    },
    "papermill": {
     "duration": 3.694825,
     "end_time": "2025-10-15T17:10:22.702388",
     "exception": false,
     "start_time": "2025-10-15T17:10:19.007563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nfor dirname, _, filenames in os.walk('/kaggle/input'):\\n    for filename in filenames:\\n        print(os.path.join(dirname, filename))\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.autograd import Function\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import shutil\n",
    "import pickle\n",
    "np.random.seed(333)\n",
    "'''\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "'''\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "322164a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:10:22.710583Z",
     "iopub.status.busy": "2025-10-15T17:10:22.709654Z",
     "iopub.status.idle": "2025-10-15T17:10:22.714870Z",
     "shell.execute_reply": "2025-10-15T17:10:22.714021Z"
    },
    "papermill": {
     "duration": 0.010881,
     "end_time": "2025-10-15T17:10:22.716664",
     "exception": false,
     "start_time": "2025-10-15T17:10:22.705783",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = \"/kaggle/input/chest-x-ray-classical-and-quantum-dataset/chestxray-conv/chestxray-conv/\"\n",
    "# Define transforms for the training and validation sets\n",
    "data_transforms ={\n",
    "    \"train_transforms\": transforms.Compose([ transforms.ToTensor()]),\n",
    "    \"valid_transforms\": transforms.Compose([ transforms.ToTensor()]), \n",
    "    \"test_transforms\": transforms.Compose([ transforms.ToTensor()])\n",
    "}\n",
    "\n",
    "# Split the dataset into train, validation and test\n",
    "train_data = 0.7\n",
    "valid_data = 0.1\n",
    "test_data = 0.2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3735713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:10:22.723818Z",
     "iopub.status.busy": "2025-10-15T17:10:22.723536Z",
     "iopub.status.idle": "2025-10-15T17:10:31.710950Z",
     "shell.execute_reply": "2025-10-15T17:10:31.709964Z"
    },
    "papermill": {
     "duration": 8.993439,
     "end_time": "2025-10-15T17:10:31.713086",
     "exception": false,
     "start_time": "2025-10-15T17:10:22.719647",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5856 5856 5856\n",
      "4099 585 1172\n",
      "Training 4099 0.6999658469945356\n",
      "Validation 585 0.09989754098360656\n",
      "Test 1172 0.20013661202185792\n",
      "4099 585 1172\n"
     ]
    }
   ],
   "source": [
    "# Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"train_transforms\"])#loading dataset\n",
    "valid_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"valid_transforms\"])\n",
    "test_data = datasets.ImageFolder(data_dir, transform=data_transforms[\"test_transforms\"])\n",
    "\n",
    "# Obtain training indices that will be used for validation and test\n",
    "num_train = len(train_data)\n",
    "print(len(train_data),len(valid_data),len(test_data))\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "train_count = int(0.7*num_train)\n",
    "valid_count = int(0.1*num_train)\n",
    "test_count = num_train - train_count - valid_count\n",
    "train_idx = indices[:train_count]\n",
    "valid_idx = indices[train_count:train_count+valid_count]\n",
    "test_idx = indices[train_count+valid_count:]\n",
    "\n",
    "print(len(train_idx), len(valid_idx), len(test_idx))\n",
    "print(\"Training\", train_count, np.sum(len(train_idx)/num_train))\n",
    "print(\"Validation\", valid_count, np.sum(len(valid_idx)/num_train))\n",
    "print(\"Test\", test_count, np.sum(len(test_idx)/num_train))\n",
    "\n",
    "# Define a custom sampler for the dataset loader avoiding recreating the dataset (just creating a new loader for each different sampling)\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "test_sampler = SubsetRandomSampler(test_idx)\n",
    "\n",
    "# Define the dataloaders using the image datasets. Dataloader is used to load our data in batches\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size = 1, sampler=train_sampler)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size = 1, sampler = valid_sampler)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size = 1, sampler = test_sampler)\n",
    "print(len(trainloader),len(validloader),len(testloader))\n",
    "\n",
    "classes=['normal','pneumonia']\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5 #unnormalize\n",
    "    plt.imshow(np.transpose(img, (1,2,0))) #convert tensor image type to numpy image type for visualization\n",
    "\n",
    "\n",
    "#Visualize some sample data\n",
    "#Obtain one batch of training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.__next__()\n",
    "images = images.numpy() #convert images to numpy for display\n",
    "\n",
    "#Plot the images in the batch, along with corresponding labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3f6caeb6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:10:31.721904Z",
     "iopub.status.busy": "2025-10-15T17:10:31.721607Z",
     "iopub.status.idle": "2025-10-15T17:10:31.727262Z",
     "shell.execute_reply": "2025-10-15T17:10:31.726384Z"
    },
    "papermill": {
     "duration": 0.01183,
     "end_time": "2025-10-15T17:10:31.728943",
     "exception": false,
     "start_time": "2025-10-15T17:10:31.717113",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfig = plt.figure(figsize=(25,4))\\nfor idx in np.arange(20):\\n    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\\n    imshow(images[idx])\\n    #ax.set_title(str(labels[idx].item()))\\n    ax.set_title(classes[labels[idx]])\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "fig = plt.figure(figsize=(25,4))\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 20/2, idx+1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    #ax.set_title(str(labels[idx].item()))\n",
    "    ax.set_title(classes[labels[idx]])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d8e2ad6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:10:31.736328Z",
     "iopub.status.busy": "2025-10-15T17:10:31.736021Z",
     "iopub.status.idle": "2025-10-15T17:10:31.748512Z",
     "shell.execute_reply": "2025-10-15T17:10:31.747805Z"
    },
    "papermill": {
     "duration": 0.018029,
     "end_time": "2025-10-15T17:10:31.750088",
     "exception": false,
     "start_time": "2025-10-15T17:10:31.732059",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.dropout = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(996496, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        self.hybrid = nn.Sigmoid()\n",
    "        #self.hybrid = Hybrid(qiskit.Aer.get_backend('aer_simulator'), 100, np.pi / 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout(x)\n",
    "        x = x.view(1, -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = self.hybrid(x)\n",
    "        return torch.cat((x, 1 - x), -1)\n",
    "\n",
    "class Net1(nn.Module):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super(Net1, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.dropout1 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=2, padding=2)\n",
    "        self.bn3 = nn.BatchNorm2d(64)\n",
    "        self.dropout2 = nn.Dropout(0.4)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        self.fc = nn.Linear(64*256*256, num_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "        self.fc2 = nn.Linear(num_classes, 1)\n",
    "        self.hybrid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.bn1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.bn2(x)\n",
    "        x = self.dropout1(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.bn3(x)\n",
    "        x = self.dropout2(x)\n",
    "        \n",
    "        x = self.flatten(x)\n",
    "        \n",
    "        x = F.relu(self.fc(x))\n",
    "        # x = self.softmax(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.hybrid(x)\n",
    "        return torch.cat((x, 1 - x), -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8ab7a08b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:10:31.757358Z",
     "iopub.status.busy": "2025-10-15T17:10:31.757007Z",
     "iopub.status.idle": "2025-10-15T17:10:31.836736Z",
     "shell.execute_reply": "2025-10-15T17:10:31.836011Z"
    },
    "papermill": {
     "duration": 0.08555,
     "end_time": "2025-10-15T17:10:31.838770",
     "exception": false,
     "start_time": "2025-10-15T17:10:31.753220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Net1()\n",
    "optimizer_transfer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion_transfer = nn.NLLLoss()\n",
    "# criterion_transfer = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 20\n",
    "loss_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ad398ce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:10:31.846841Z",
     "iopub.status.busy": "2025-10-15T17:10:31.846102Z",
     "iopub.status.idle": "2025-10-15T17:10:34.465618Z",
     "shell.execute_reply": "2025-10-15T17:10:34.464611Z"
    },
    "papermill": {
     "duration": 2.625541,
     "end_time": "2025-10-15T17:10:34.467677",
     "exception": false,
     "start_time": "2025-10-15T17:10:31.842136",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Specify loss function and optimizer\n",
    "#criterion_transfer = nn.CrossEntropyLoss()\n",
    "#optimizer_transfer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "if use_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb4b47c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:10:34.475773Z",
     "iopub.status.busy": "2025-10-15T17:10:34.475514Z",
     "iopub.status.idle": "2025-10-15T17:35:12.621483Z",
     "shell.execute_reply": "2025-10-15T17:35:12.620010Z"
    },
    "papermill": {
     "duration": 1478.155512,
     "end_time": "2025-10-15T17:35:12.626751",
     "exception": false,
     "start_time": "2025-10-15T17:10:34.471239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1 \tTraining Loss: -0.60530-0.6053 \tValidation Loss: -0.65709\n",
      "Validation loss decreased (inf --> -0.65709). Saving model ...\n",
      "Epoch: 2 \tTraining Loss: -0.67974-0.6797 \tValidation Loss: -0.71891\n",
      "Validation loss decreased (-0.65709 --> -0.71891). Saving model ...\n",
      "Epoch: 3 \tTraining Loss: -0.71839-0.7184 \tValidation Loss: -0.74355\n",
      "Validation loss decreased (-0.71891 --> -0.74355). Saving model ...\n",
      "Epoch: 4 \tTraining Loss: -0.73017-0.7302 \tValidation Loss: -0.74355\n",
      "Validation loss decreased (-0.74355 --> -0.74355). Saving model ...\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    '''returns trained model'''\n",
    "    # Initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.inf\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        total_loss = []\n",
    "        # In the training loop, I track down the loss\n",
    "        # Initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        model = model.cuda()\n",
    "\n",
    "        # Model training\n",
    "        model.train()\n",
    "        for batch_idx, (data,target) in enumerate(trainloader):\n",
    "            # 1st step: Move to GPU\n",
    "            if use_cuda:\n",
    "                data,target = data.cuda(), target.cuda()\n",
    "\n",
    "            # Then, clear (zero out) the gradient of all optimized variables\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data).to(device)\n",
    "            # Perform the Cross Entropy Loss. Calculate the batch loss.\n",
    "            loss = criterion(output, target)\n",
    "            # Backward pass: compute gradient of the loss with respect to model parameters\n",
    "            loss.backward()\n",
    "            # Perform optimization step (parameter update)\n",
    "            optimizer.step()\n",
    "            # Record the average training loss\n",
    "            train_loss = train_loss + ((1/ (batch_idx + 1 ))*(loss.data-train_loss))\n",
    "            total_loss.append(loss.item())\n",
    "        loss_list.append(sum(total_loss)/len(total_loss))\n",
    "\n",
    "        # Model validation\n",
    "        model.eval()\n",
    "        for batch_idx, (data,target) in enumerate(validloader):\n",
    "            # Move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # Update the average validation loss\n",
    "            # Forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data).to(device)\n",
    "            # Calculate the batch loss\n",
    "            loss = criterion(output, target)\n",
    "            # Update the average validation loss\n",
    "            valid_loss = valid_loss + ((1/ (batch_idx +1)) * (loss.data - valid_loss))\n",
    "\n",
    "        # print training/validation stats\n",
    "        print('Epoch: {} \\tTraining Loss: {:.5f}{:.4f} \\tValidation Loss: {:.5f}'.format(\n",
    "            epoch,\n",
    "            train_loss,\n",
    "            loss_list[-1],\n",
    "            valid_loss))\n",
    "\n",
    "        # Save the model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.5f} --> {:.5f}). Saving model ...'.format(\n",
    "                valid_loss_min,\n",
    "                valid_loss))\n",
    "            torch.save(model.state_dict(), os.path.join('model_transfer.pt'))\n",
    "            valid_loss_min = valid_loss\n",
    "\n",
    "    # Return trained model\n",
    "    return model\n",
    "\n",
    "# Define loaders transfer\n",
    "loaders_transfer = {'train': trainloader,\n",
    "                    'valid': validloader,\n",
    "                    'test': testloader}\n",
    "\n",
    "# Train the model\n",
    "model_transfer = train(4, loaders_transfer, model, optimizer_transfer, criterion_transfer, use_cuda, os.path.join('model_transfer.pt'))\n",
    "\n",
    "\n",
    "# Load the model that got the best validation accuracy\n",
    "# model_transfer.load_state_dict(torch.load(os.path.join('model_transfer.pt')))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68ac4cfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:35:12.635393Z",
     "iopub.status.busy": "2025-10-15T17:35:12.634689Z",
     "iopub.status.idle": "2025-10-15T17:35:12.882755Z",
     "shell.execute_reply": "2025-10-15T17:35:12.881913Z"
    },
    "papermill": {
     "duration": 0.254629,
     "end_time": "2025-10-15T17:35:12.884707",
     "exception": false,
     "start_time": "2025-10-15T17:35:12.630078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Neg Log Likelihood Loss')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_list)\n",
    "plt.title('Hybrid NN Training Convergence')\n",
    "plt.xlabel('Training Iterations')\n",
    "plt.ylabel('Neg Log Likelihood Loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c1ec1bf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:35:12.893847Z",
     "iopub.status.busy": "2025-10-15T17:35:12.893602Z",
     "iopub.status.idle": "2025-10-15T17:36:04.731883Z",
     "shell.execute_reply": "2025-10-15T17:36:04.730994Z"
    },
    "papermill": {
     "duration": 51.852937,
     "end_time": "2025-10-15T17:36:04.741739",
     "exception": false,
     "start_time": "2025-10-15T17:35:12.888802",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: -0.720860\n",
      "\n",
      "\n",
      "Test Accuracy: 72% (845/1172)\n",
      "OrderedDict([('conv1.weight', tensor([[[[ 0.0652,  0.0735, -0.0642],\n",
      "          [ 0.0937, -0.0340,  0.1075],\n",
      "          [ 0.0286, -0.1170,  0.1953]],\n",
      "\n",
      "         [[-0.0601, -0.1126, -0.1433],\n",
      "          [-0.1495, -0.0477,  0.1916],\n",
      "          [ 0.1183, -0.1187,  0.0570]],\n",
      "\n",
      "         [[ 0.1361,  0.0664, -0.0656],\n",
      "          [ 0.2045, -0.2311,  0.0637],\n",
      "          [-0.0849, -0.1326,  0.1322]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1198,  0.0595,  0.1234],\n",
      "          [ 0.0084, -0.0505, -0.0169],\n",
      "          [-0.1251, -0.0822,  0.0281]],\n",
      "\n",
      "         [[ 0.2381,  0.0722, -0.1284],\n",
      "          [ 0.0066, -0.0414,  0.0586],\n",
      "          [ 0.1835,  0.1592, -0.1687]],\n",
      "\n",
      "         [[ 0.1423, -0.1432,  0.0923],\n",
      "          [ 0.0110,  0.1418,  0.1438],\n",
      "          [ 0.0971,  0.1038,  0.1680]]],\n",
      "\n",
      "\n",
      "        [[[-0.0944, -0.1303,  0.1760],\n",
      "          [-0.0357, -0.0678, -0.1459],\n",
      "          [-0.0102,  0.1647,  0.0573]],\n",
      "\n",
      "         [[-0.0384,  0.1272, -0.2036],\n",
      "          [ 0.0264, -0.0399, -0.0985],\n",
      "          [ 0.0814,  0.0798,  0.1127]],\n",
      "\n",
      "         [[ 0.1073, -0.1707, -0.1194],\n",
      "          [ 0.1062, -0.0046, -0.1843],\n",
      "          [ 0.0823, -0.1651, -0.1426]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1954,  0.0707,  0.0566],\n",
      "          [ 0.0846, -0.1025, -0.2272],\n",
      "          [ 0.1154, -0.1027,  0.0331]],\n",
      "\n",
      "         [[ 0.0872, -0.0286,  0.0017],\n",
      "          [-0.0132, -0.1470, -0.1063],\n",
      "          [ 0.0923,  0.0211,  0.1250]],\n",
      "\n",
      "         [[ 0.0480, -0.0808, -0.2021],\n",
      "          [ 0.1670,  0.1419, -0.1600],\n",
      "          [-0.1148, -0.1000, -0.1396]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0676, -0.1839, -0.0082],\n",
      "          [ 0.0338,  0.0742, -0.0600],\n",
      "          [-0.0281, -0.1068,  0.0141]],\n",
      "\n",
      "         [[-0.1859,  0.0881,  0.0488],\n",
      "          [-0.1690,  0.1215, -0.0928],\n",
      "          [-0.0659, -0.0808, -0.1587]],\n",
      "\n",
      "         [[ 0.1387,  0.1370,  0.1932],\n",
      "          [-0.0918, -0.0573,  0.1627],\n",
      "          [-0.1898,  0.1718, -0.0832]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1059, -0.1940,  0.0261],\n",
      "          [ 0.0289, -0.0771, -0.0521],\n",
      "          [ 0.1757,  0.0729, -0.0990]],\n",
      "\n",
      "         [[ 0.0796, -0.0310,  0.0521],\n",
      "          [-0.1789,  0.0035, -0.1395],\n",
      "          [-0.1392,  0.1071,  0.1432]],\n",
      "\n",
      "         [[-0.0787, -0.0550,  0.0405],\n",
      "          [-0.0633, -0.0474,  0.0329],\n",
      "          [-0.1629, -0.0851,  0.0501]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1028, -0.1950,  0.0148],\n",
      "          [ 0.0998, -0.1934, -0.1469],\n",
      "          [ 0.0175, -0.1956,  0.0341]],\n",
      "\n",
      "         [[ 0.0686, -0.1011, -0.1112],\n",
      "          [ 0.1460,  0.1514, -0.0017],\n",
      "          [-0.0909, -0.1027,  0.0881]],\n",
      "\n",
      "         [[ 0.0278,  0.0463, -0.2017],\n",
      "          [ 0.1627, -0.0501,  0.0162],\n",
      "          [ 0.0947, -0.0505, -0.1353]]],\n",
      "\n",
      "\n",
      "        [[[-0.1389,  0.0704, -0.0008],\n",
      "          [ 0.0086, -0.1346,  0.1148],\n",
      "          [-0.1888,  0.0023,  0.0180]],\n",
      "\n",
      "         [[ 0.1316,  0.1220, -0.0624],\n",
      "          [-0.1963,  0.0111,  0.0786],\n",
      "          [-0.0464, -0.0811, -0.1269]],\n",
      "\n",
      "         [[ 0.0051, -0.0769, -0.1765],\n",
      "          [ 0.0802, -0.1406, -0.0663],\n",
      "          [ 0.1010,  0.0064,  0.0917]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1818, -0.0594, -0.0006],\n",
      "          [-0.0033, -0.0549,  0.0048],\n",
      "          [-0.0961,  0.0874, -0.1585]],\n",
      "\n",
      "         [[-0.1445, -0.1277,  0.0727],\n",
      "          [-0.0308, -0.0933, -0.0288],\n",
      "          [ 0.0147,  0.0071,  0.0213]],\n",
      "\n",
      "         [[-0.1830, -0.0361,  0.1149],\n",
      "          [ 0.0406,  0.0726, -0.0354],\n",
      "          [ 0.0096, -0.1823,  0.0071]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0925,  0.0194,  0.1286],\n",
      "          [-0.0618,  0.0512,  0.1429],\n",
      "          [ 0.0790,  0.1027,  0.0351]],\n",
      "\n",
      "         [[ 0.1792,  0.1675, -0.1072],\n",
      "          [ 0.1233,  0.1643,  0.1156],\n",
      "          [-0.0445,  0.0374,  0.0400]],\n",
      "\n",
      "         [[ 0.0659,  0.0072,  0.1820],\n",
      "          [ 0.1829,  0.0131,  0.0108],\n",
      "          [-0.1190,  0.0875, -0.0887]]],\n",
      "\n",
      "\n",
      "        [[[-0.2389,  0.0567,  0.1963],\n",
      "          [-0.2110,  0.1307, -0.1148],\n",
      "          [-0.2330,  0.0206, -0.0852]],\n",
      "\n",
      "         [[ 0.0970, -0.1635,  0.1901],\n",
      "          [ 0.0051, -0.1933,  0.1708],\n",
      "          [-0.2145, -0.1854,  0.2024]],\n",
      "\n",
      "         [[-0.0229,  0.1268, -0.1129],\n",
      "          [-0.2238, -0.1430,  0.0316],\n",
      "          [-0.1434,  0.0650, -0.0733]]],\n",
      "\n",
      "\n",
      "        [[[-0.0981,  0.1359,  0.1670],\n",
      "          [-0.1259,  0.1263,  0.1518],\n",
      "          [-0.1235,  0.0808, -0.0940]],\n",
      "\n",
      "         [[-0.0950,  0.1879, -0.1295],\n",
      "          [-0.1383,  0.1388,  0.1971],\n",
      "          [-0.1570, -0.0611,  0.2005]],\n",
      "\n",
      "         [[-0.0844,  0.2080,  0.1447],\n",
      "          [ 0.1842, -0.0152, -0.0087],\n",
      "          [ 0.1356,  0.0536,  0.0966]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0955, -0.0924, -0.0077],\n",
      "          [ 0.0624,  0.1194,  0.0120],\n",
      "          [-0.0785, -0.0399, -0.0935]],\n",
      "\n",
      "         [[ 0.0678,  0.0754, -0.0688],\n",
      "          [ 0.1467,  0.0895, -0.0155],\n",
      "          [ 0.2016,  0.0024, -0.1459]],\n",
      "\n",
      "         [[-0.0131,  0.0654, -0.0059],\n",
      "          [ 0.1564, -0.0986,  0.0522],\n",
      "          [ 0.1708, -0.0818, -0.0796]]],\n",
      "\n",
      "\n",
      "        [[[-0.0352,  0.1402,  0.0106],\n",
      "          [ 0.0737,  0.1884,  0.2075],\n",
      "          [ 0.0051,  0.0124,  0.0603]],\n",
      "\n",
      "         [[ 0.0029,  0.1135,  0.0977],\n",
      "          [ 0.2496,  0.1616,  0.0979],\n",
      "          [-0.0712,  0.1570, -0.1635]],\n",
      "\n",
      "         [[-0.0575,  0.1547, -0.1182],\n",
      "          [ 0.1597,  0.2285, -0.0459],\n",
      "          [ 0.1085,  0.1336,  0.1626]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1396,  0.0433,  0.0978],\n",
      "          [ 0.0690, -0.1160, -0.2142],\n",
      "          [-0.0221, -0.2238, -0.1011]],\n",
      "\n",
      "         [[ 0.1480, -0.1241,  0.1000],\n",
      "          [ 0.1573, -0.2166, -0.0249],\n",
      "          [ 0.0797,  0.0484, -0.0929]],\n",
      "\n",
      "         [[-0.1461,  0.0985, -0.1085],\n",
      "          [ 0.0207, -0.1519, -0.2196],\n",
      "          [-0.0160,  0.0226, -0.0232]]],\n",
      "\n",
      "\n",
      "        [[[-0.1335,  0.1233, -0.1738],\n",
      "          [-0.0177,  0.1037, -0.0187],\n",
      "          [ 0.2027, -0.0076, -0.0772]],\n",
      "\n",
      "         [[-0.1222,  0.1493,  0.1075],\n",
      "          [ 0.2004,  0.0169,  0.1144],\n",
      "          [-0.1613,  0.0353,  0.0612]],\n",
      "\n",
      "         [[-0.0229, -0.0755, -0.2206],\n",
      "          [ 0.0380, -0.0688, -0.1559],\n",
      "          [ 0.1394, -0.1044, -0.0546]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0981, -0.1981, -0.0627],\n",
      "          [-0.0586,  0.1780,  0.0449],\n",
      "          [ 0.0818, -0.1776, -0.0492]],\n",
      "\n",
      "         [[ 0.1278, -0.2057, -0.0882],\n",
      "          [-0.0791,  0.0495,  0.0435],\n",
      "          [ 0.0948, -0.0339,  0.0294]],\n",
      "\n",
      "         [[-0.1859,  0.0173,  0.0673],\n",
      "          [ 0.1217, -0.0056, -0.1053],\n",
      "          [-0.1496,  0.1272, -0.0414]]],\n",
      "\n",
      "\n",
      "        [[[ 0.2418,  0.1558,  0.0521],\n",
      "          [-0.0232, -0.1131, -0.1276],\n",
      "          [ 0.0670, -0.1018,  0.0294]],\n",
      "\n",
      "         [[-0.1356, -0.1200, -0.0503],\n",
      "          [ 0.2019, -0.0333,  0.1587],\n",
      "          [ 0.1613,  0.1737, -0.1575]],\n",
      "\n",
      "         [[ 0.1915, -0.0504, -0.0581],\n",
      "          [ 0.0233, -0.0140, -0.0554],\n",
      "          [-0.0222,  0.1596, -0.1024]]],\n",
      "\n",
      "\n",
      "        [[[-0.0549,  0.1954, -0.0735],\n",
      "          [-0.1620, -0.0725, -0.0341],\n",
      "          [-0.1085,  0.2012, -0.0190]],\n",
      "\n",
      "         [[-0.1926,  0.1090,  0.1962],\n",
      "          [ 0.0348,  0.0185,  0.0522],\n",
      "          [ 0.1558,  0.0161,  0.0501]],\n",
      "\n",
      "         [[-0.2123, -0.0025,  0.1747],\n",
      "          [ 0.0434, -0.0946, -0.0270],\n",
      "          [ 0.1076, -0.1211,  0.1812]]],\n",
      "\n",
      "\n",
      "        [[[-0.0323, -0.0308, -0.0841],\n",
      "          [ 0.1343, -0.1105, -0.1265],\n",
      "          [ 0.0904, -0.1720,  0.0552]],\n",
      "\n",
      "         [[ 0.0509,  0.0254,  0.0656],\n",
      "          [-0.1157, -0.0556, -0.1166],\n",
      "          [ 0.0745, -0.0041, -0.0479]],\n",
      "\n",
      "         [[-0.0352, -0.0086, -0.0695],\n",
      "          [ 0.0366, -0.0302,  0.1450],\n",
      "          [ 0.1045,  0.0905, -0.0627]]],\n",
      "\n",
      "\n",
      "        [[[-0.1958, -0.0936,  0.1518],\n",
      "          [-0.0190, -0.0828,  0.1747],\n",
      "          [ 0.1867, -0.0322,  0.0363]],\n",
      "\n",
      "         [[-0.1144, -0.1334, -0.0797],\n",
      "          [-0.1390,  0.1496, -0.1308],\n",
      "          [ 0.0388, -0.0440, -0.0025]],\n",
      "\n",
      "         [[-0.0191, -0.0910,  0.2021],\n",
      "          [ 0.1771,  0.0596, -0.0402],\n",
      "          [ 0.0168, -0.0821,  0.0198]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1966,  0.2161, -0.0915],\n",
      "          [ 0.1612,  0.2113,  0.0946],\n",
      "          [-0.1595, -0.1039, -0.0403]],\n",
      "\n",
      "         [[ 0.1605,  0.1426,  0.0521],\n",
      "          [-0.0453,  0.1743,  0.0553],\n",
      "          [-0.0981,  0.1298,  0.1659]],\n",
      "\n",
      "         [[-0.0143,  0.1335,  0.1846],\n",
      "          [ 0.1505,  0.0527,  0.0600],\n",
      "          [-0.0530,  0.2388, -0.0489]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0329,  0.1334,  0.0251],\n",
      "          [ 0.0447,  0.1258, -0.1914],\n",
      "          [ 0.2198,  0.1456, -0.1110]],\n",
      "\n",
      "         [[-0.0860,  0.2117,  0.0622],\n",
      "          [ 0.1617,  0.0875,  0.1675],\n",
      "          [-0.0248, -0.0671,  0.1534]],\n",
      "\n",
      "         [[-0.0553, -0.0484, -0.0419],\n",
      "          [ 0.0057,  0.1470,  0.1262],\n",
      "          [ 0.1555, -0.0433,  0.0212]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0512, -0.0618, -0.0238],\n",
      "          [ 0.1740,  0.1615, -0.0044],\n",
      "          [ 0.0546,  0.1776, -0.0096]],\n",
      "\n",
      "         [[ 0.1924,  0.1260, -0.0586],\n",
      "          [-0.1418,  0.1924, -0.1524],\n",
      "          [-0.0106, -0.1481,  0.0232]],\n",
      "\n",
      "         [[-0.1241,  0.0477, -0.1346],\n",
      "          [ 0.0542,  0.1124,  0.1246],\n",
      "          [ 0.0499,  0.1333, -0.1742]]],\n",
      "\n",
      "\n",
      "        [[[-0.1421, -0.1521,  0.0052],\n",
      "          [ 0.2107,  0.0593,  0.1487],\n",
      "          [ 0.0050, -0.2069,  0.0150]],\n",
      "\n",
      "         [[ 0.1645,  0.0957,  0.0119],\n",
      "          [ 0.0211, -0.2044,  0.0459],\n",
      "          [ 0.0533,  0.0299, -0.0778]],\n",
      "\n",
      "         [[-0.1508,  0.0050,  0.1641],\n",
      "          [ 0.0605, -0.1970,  0.0644],\n",
      "          [ 0.1180,  0.0726, -0.0292]]],\n",
      "\n",
      "\n",
      "        [[[-0.0771, -0.1782, -0.1280],\n",
      "          [-0.1241,  0.0538,  0.1883],\n",
      "          [ 0.0684,  0.0173, -0.0677]],\n",
      "\n",
      "         [[ 0.1176, -0.0203, -0.0139],\n",
      "          [ 0.0058,  0.1370,  0.0531],\n",
      "          [ 0.0513, -0.0841, -0.1815]],\n",
      "\n",
      "         [[-0.0902,  0.1462, -0.0599],\n",
      "          [ 0.1576, -0.2077,  0.1181],\n",
      "          [-0.0424, -0.1095, -0.1579]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1093, -0.1077,  0.1884],\n",
      "          [-0.0806, -0.1295,  0.1328],\n",
      "          [ 0.0309, -0.0629,  0.0774]],\n",
      "\n",
      "         [[ 0.1936,  0.1764, -0.1009],\n",
      "          [-0.0823, -0.1996,  0.0027],\n",
      "          [-0.0507,  0.1253,  0.1487]],\n",
      "\n",
      "         [[ 0.0181, -0.1906,  0.1894],\n",
      "          [-0.0320, -0.0830, -0.1493],\n",
      "          [ 0.1189, -0.1032, -0.0292]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0828, -0.0429,  0.0772],\n",
      "          [-0.0483, -0.0904, -0.1320],\n",
      "          [ 0.0497,  0.0725,  0.0191]],\n",
      "\n",
      "         [[ 0.1885, -0.1976, -0.0703],\n",
      "          [ 0.0075, -0.1883, -0.1381],\n",
      "          [-0.0203, -0.1811, -0.0864]],\n",
      "\n",
      "         [[-0.0951, -0.2168,  0.1269],\n",
      "          [ 0.1389,  0.0333,  0.1137],\n",
      "          [ 0.0229, -0.1157,  0.1604]]],\n",
      "\n",
      "\n",
      "        [[[-0.0200, -0.0083, -0.0096],\n",
      "          [ 0.0324, -0.0448,  0.0700],\n",
      "          [-0.0877,  0.1145, -0.0018]],\n",
      "\n",
      "         [[-0.1660,  0.0865, -0.1224],\n",
      "          [-0.1465,  0.0257, -0.1421],\n",
      "          [-0.1643,  0.1048, -0.1357]],\n",
      "\n",
      "         [[-0.2346, -0.0414, -0.0855],\n",
      "          [-0.0391, -0.1880, -0.0241],\n",
      "          [-0.1535, -0.1403, -0.1402]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0885, -0.1095,  0.0684],\n",
      "          [ 0.1148,  0.0165, -0.0960],\n",
      "          [ 0.0963, -0.1848, -0.1077]],\n",
      "\n",
      "         [[-0.1469,  0.1616, -0.0496],\n",
      "          [-0.0737, -0.1091, -0.0964],\n",
      "          [-0.0360, -0.1471, -0.1526]],\n",
      "\n",
      "         [[ 0.0422, -0.1304,  0.1139],\n",
      "          [-0.0981,  0.1859,  0.0826],\n",
      "          [ 0.0211, -0.1758, -0.1799]]],\n",
      "\n",
      "\n",
      "        [[[ 0.0264,  0.2328, -0.0876],\n",
      "          [-0.1176,  0.2292,  0.0650],\n",
      "          [ 0.1082,  0.1720,  0.1101]],\n",
      "\n",
      "         [[ 0.1193, -0.0955,  0.2071],\n",
      "          [ 0.1379,  0.0220, -0.1125],\n",
      "          [-0.1068,  0.0608, -0.1299]],\n",
      "\n",
      "         [[-0.0053,  0.1390, -0.0626],\n",
      "          [ 0.1004,  0.0753, -0.1492],\n",
      "          [ 0.1670,  0.1705, -0.1321]]],\n",
      "\n",
      "\n",
      "        [[[ 0.1401,  0.0534,  0.0896],\n",
      "          [ 0.0106, -0.0648, -0.1759],\n",
      "          [-0.1338,  0.1704, -0.0887]],\n",
      "\n",
      "         [[-0.0318,  0.0636,  0.1534],\n",
      "          [ 0.0170,  0.1164, -0.0825],\n",
      "          [-0.0072,  0.1291, -0.0311]],\n",
      "\n",
      "         [[ 0.0570,  0.0681,  0.0674],\n",
      "          [-0.1172, -0.0395, -0.0163],\n",
      "          [ 0.0216, -0.1130, -0.1491]]]], device='cuda:0')), ('conv1.bias', tensor([-0.1104,  0.0148, -0.1691, -0.0261, -0.1303,  0.0880, -0.2006,  0.0057,\n",
      "         0.0167,  0.1032,  0.1201,  0.2039,  0.2105, -0.0109,  0.0456, -0.0672,\n",
      "         0.1111,  0.0393, -0.0813, -0.0882,  0.1303,  0.0520, -0.0003,  0.1740,\n",
      "         0.0909, -0.1366, -0.0204, -0.2170,  0.0232,  0.1213, -0.0467, -0.0445],\n",
      "       device='cuda:0')), ('bn1.weight', tensor([1.0412, 0.9681, 0.9694, 0.9616, 0.9972, 0.9562, 1.0166, 1.0150, 1.0000,\n",
      "        1.0184, 0.9897, 1.0335, 1.0140, 1.0454, 1.0375, 1.0027, 1.0355, 0.9937,\n",
      "        1.0259, 1.0000, 0.9961, 1.0136, 1.0437, 1.0928, 1.0244, 0.9662, 0.9988,\n",
      "        1.0270, 1.0265, 1.0000, 1.0495, 1.0156], device='cuda:0')), ('bn1.bias', tensor([-0.0012, -0.0401,  0.0162,  0.0351, -0.0636,  0.0178, -0.0388,  0.0107,\n",
      "         0.0128, -0.0756,  0.0451, -0.0921, -0.0420, -0.0636, -0.0015,  0.0304,\n",
      "         0.0300,  0.0403, -0.0440,  0.0173, -0.0140, -0.0997, -0.0830,  0.0328,\n",
      "        -0.0095, -0.0064,  0.0152, -0.0441,  0.0149, -0.0077, -0.0293, -0.0459],\n",
      "       device='cuda:0')), ('bn1.running_mean', tensor([1.1931e-01, 6.6182e-01, 5.6052e-45, 1.7172e-02, 3.8077e-03, 1.6702e-03,\n",
      "        5.6052e-45, 5.6052e-45, 0.0000e+00, 9.6876e-01, 1.4884e-02, 7.8466e-01,\n",
      "        4.7862e-01, 1.0849e+00, 5.6052e-45, 2.3915e-02, 1.4850e-02, 2.9196e-01,\n",
      "        1.3872e-01, 0.0000e+00, 1.2276e-01, 1.0893e+00, 7.3104e-01, 5.1386e-01,\n",
      "        2.2945e-01, 7.9780e-05, 1.3243e-01, 8.1016e-03, 5.6052e-45, 0.0000e+00,\n",
      "        5.6933e-01, 7.5751e-02], device='cuda:0')), ('bn1.running_var', tensor([3.2611e-02, 4.4151e-02, 5.6052e-45, 2.8322e-03, 5.6145e-04, 6.2468e-05,\n",
      "        5.6052e-45, 5.6052e-45, 5.6052e-45, 4.1349e-02, 2.5299e-03, 7.4885e-02,\n",
      "        3.8929e-02, 9.2147e-02, 5.6052e-45, 3.4620e-03, 1.6198e-03, 2.3349e-02,\n",
      "        1.9943e-02, 5.6052e-45, 1.4651e-02, 8.2062e-02, 3.4369e-02, 5.4770e-02,\n",
      "        4.2473e-02, 1.9809e-06, 2.9961e-02, 4.3063e-04, 5.6052e-45, 5.6052e-45,\n",
      "        7.2224e-02, 1.2611e-02], device='cuda:0')), ('bn1.num_batches_tracked', tensor(16396, device='cuda:0')), ('conv2.weight', tensor([[[[-4.1186e-02,  4.8822e-02,  1.9586e-02,  6.6996e-02, -1.2244e-03],\n",
      "          [-5.6622e-02,  7.5067e-02,  1.4792e-02,  3.2694e-02, -1.6877e-02],\n",
      "          [-1.0618e-02,  5.5327e-02, -1.5388e-02,  1.6189e-02,  1.1611e-02],\n",
      "          [-1.7775e-02,  1.5809e-02,  1.7066e-02,  4.4598e-02,  4.6601e-02],\n",
      "          [ 1.4635e-03, -1.9959e-02,  4.4543e-02,  1.0125e-01, -1.0079e-02]],\n",
      "\n",
      "         [[ 2.9166e-02,  4.7710e-02, -1.8618e-02, -2.9240e-02,  1.4207e-03],\n",
      "          [-3.6612e-02,  1.1702e-02, -5.1491e-02, -2.5723e-02, -2.3675e-02],\n",
      "          [-3.3163e-02,  7.7562e-02, -4.5747e-03,  2.0744e-02, -3.5504e-02],\n",
      "          [-1.3964e-02,  8.7218e-03, -5.4436e-02, -3.5802e-02, -1.9704e-02],\n",
      "          [ 3.0943e-02,  1.6845e-02, -1.7272e-02,  5.0801e-02, -2.5626e-02]],\n",
      "\n",
      "         [[ 1.5782e-03, -3.0183e-03,  4.2983e-03,  2.3461e-02,  4.6738e-02],\n",
      "          [ 3.0677e-02,  4.6563e-03,  6.8560e-02, -3.5171e-03,  4.1353e-02],\n",
      "          [ 3.6393e-02, -2.1381e-02,  4.7501e-02,  1.8286e-02,  7.0060e-02],\n",
      "          [ 5.8596e-02, -3.9481e-02,  4.8537e-02,  1.2213e-02,  4.5844e-02],\n",
      "          [ 6.0024e-02, -3.4397e-02,  1.7222e-02,  1.3884e-02,  5.9500e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.6828e-03,  3.1043e-02,  4.2494e-02,  5.1010e-02,  4.2464e-02],\n",
      "          [ 2.8758e-02,  5.9909e-02,  1.0159e-02,  5.4062e-02,  4.8360e-02],\n",
      "          [ 6.9443e-03,  1.7570e-02,  5.2272e-02,  1.1711e-02,  3.8233e-02],\n",
      "          [-1.1493e-03,  2.3011e-02,  2.7418e-02,  6.3930e-02,  2.7651e-03],\n",
      "          [ 1.3899e-02,  6.7341e-03,  6.1580e-03,  4.2207e-02,  3.1082e-03]],\n",
      "\n",
      "         [[ 6.2710e-02,  8.2838e-02,  6.8107e-03, -3.3152e-02,  1.4534e-02],\n",
      "          [ 1.1121e-01,  5.1396e-02,  4.2130e-03, -2.4287e-03,  2.6709e-03],\n",
      "          [ 1.2302e-01,  7.3582e-02,  2.9561e-02,  1.0042e-02,  3.6493e-02],\n",
      "          [ 1.2033e-01,  9.1553e-02, -1.8969e-02, -1.4777e-02,  7.2046e-02],\n",
      "          [ 6.4846e-02,  1.0438e-01, -1.6174e-02, -8.1445e-02,  9.1628e-02]],\n",
      "\n",
      "         [[-5.8614e-03, -4.3207e-02, -9.3472e-03,  2.6706e-02,  2.1154e-02],\n",
      "          [ 2.9787e-02, -3.3824e-02,  3.9805e-02,  3.4178e-02,  4.1121e-02],\n",
      "          [ 5.9017e-03,  2.5499e-02,  1.6025e-02,  2.5914e-02,  2.5962e-02],\n",
      "          [ 6.2138e-03,  9.7516e-03, -4.8373e-03, -2.5324e-03, -1.7778e-02],\n",
      "          [ 4.4178e-02,  4.9458e-02,  3.4488e-02, -1.1213e-02,  5.2915e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.6891e-02,  1.0526e-01, -4.8378e-02,  5.8079e-02,  7.9454e-03],\n",
      "          [-6.3879e-04,  6.7814e-02, -6.8425e-02,  1.1258e-02, -7.6814e-03],\n",
      "          [-4.4014e-02,  1.1122e-01, -3.6581e-02,  1.7302e-02, -3.7274e-02],\n",
      "          [-7.9849e-02,  9.7672e-02, -6.8584e-02,  3.1138e-02, -3.6111e-02],\n",
      "          [-6.8537e-02,  1.1139e-01, -5.5270e-02, -4.7556e-02, -2.5238e-02]],\n",
      "\n",
      "         [[-2.4636e-02,  5.0922e-02,  4.2063e-03,  3.9123e-02, -2.9529e-02],\n",
      "          [-1.0001e-02,  9.2940e-02, -3.9195e-02,  8.1675e-02,  6.0687e-03],\n",
      "          [-2.4253e-03,  1.0667e-01, -1.9819e-02,  8.9868e-02,  1.0597e-02],\n",
      "          [-2.5262e-02,  9.9391e-02,  1.2269e-02,  6.5955e-02, -1.5929e-02],\n",
      "          [-1.7196e-02,  1.0635e-01, -1.6526e-02,  1.0462e-02, -2.7139e-02]],\n",
      "\n",
      "         [[ 4.9402e-02,  5.9357e-02,  2.2696e-02,  3.5117e-02,  1.8969e-02],\n",
      "          [ 4.7129e-02,  1.7399e-02,  1.1135e-02,  6.3353e-03,  2.3629e-02],\n",
      "          [ 1.0881e-02,  2.1170e-02,  3.1248e-03,  2.0754e-02,  5.8603e-02],\n",
      "          [ 4.3500e-02, -9.9863e-03,  4.4582e-02,  3.8795e-02,  2.9797e-02],\n",
      "          [ 1.0389e-02, -5.8704e-03,  5.7274e-03,  3.4123e-02,  3.2405e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 6.9787e-02,  6.6634e-02,  3.5838e-02,  7.3288e-02,  4.7552e-02],\n",
      "          [ 6.2326e-02,  3.3611e-02,  6.0437e-02,  5.0367e-02,  2.1110e-02],\n",
      "          [ 5.8098e-02,  6.7950e-02,  3.2890e-02,  8.0467e-02,  3.0739e-02],\n",
      "          [ 7.7424e-02,  4.1451e-02,  3.9397e-02,  5.6491e-02,  2.1038e-02],\n",
      "          [ 2.1575e-02,  5.8572e-02,  6.1267e-02,  3.2613e-02,  2.3387e-02]],\n",
      "\n",
      "         [[ 8.2841e-02,  6.3655e-02, -1.5080e-02,  2.4044e-02,  2.6074e-02],\n",
      "          [ 5.3253e-02,  4.6496e-02,  2.0177e-02, -2.3653e-02,  3.8542e-02],\n",
      "          [ 6.9481e-02, -3.8504e-04,  4.4734e-02, -1.4507e-02,  3.6646e-02],\n",
      "          [ 3.8407e-02,  7.2914e-02,  1.0941e-02,  2.8326e-02,  1.0423e-02],\n",
      "          [ 4.3241e-02,  2.8243e-02, -2.8254e-02, -4.8963e-03,  2.5745e-02]],\n",
      "\n",
      "         [[-2.0619e-02, -1.2674e-02, -1.4450e-02, -4.4163e-02,  2.2946e-02],\n",
      "          [ 8.6710e-03, -3.1259e-02,  3.6098e-02,  2.2477e-02, -1.2972e-02],\n",
      "          [ 4.3488e-02,  2.5379e-02,  1.3727e-02, -1.8295e-02,  3.3146e-02],\n",
      "          [-4.2618e-03, -1.9331e-02,  1.2070e-02, -2.5192e-02, -3.4083e-04],\n",
      "          [ 3.3527e-02, -7.9855e-03,  3.3691e-02, -3.3823e-02,  2.7555e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 4.2476e-02, -6.3230e-02,  2.4626e-02, -8.5705e-02, -5.3308e-03],\n",
      "          [ 5.0440e-03, -2.0685e-02,  8.8112e-02, -8.8229e-02,  3.5964e-02],\n",
      "          [ 2.6536e-02, -7.2832e-02,  3.5946e-02, -8.3924e-02,  5.6052e-03],\n",
      "          [-4.0211e-03, -2.6790e-02,  5.3756e-02, -1.0079e-01, -1.1232e-02],\n",
      "          [-3.4483e-03, -2.7738e-02,  6.3559e-02, -7.2411e-02, -2.4154e-02]],\n",
      "\n",
      "         [[ 8.0279e-03, -1.2817e-02,  5.0642e-02, -8.9946e-02, -5.4832e-02],\n",
      "          [ 3.0087e-02,  1.5169e-02,  6.9074e-02, -6.8308e-02,  5.7782e-03],\n",
      "          [ 2.5787e-02, -4.3505e-02,  6.6546e-02, -6.1086e-02, -4.4528e-02],\n",
      "          [-8.9942e-03, -5.4171e-02,  6.8995e-02, -9.0053e-02,  2.0818e-02],\n",
      "          [-1.9214e-02, -4.6053e-02,  7.9656e-02, -7.3328e-02, -1.4707e-02]],\n",
      "\n",
      "         [[-4.8559e-02, -2.8066e-02, -1.7609e-02,  1.7634e-02, -3.1679e-02],\n",
      "          [-1.6207e-02, -7.3232e-03, -4.9254e-02, -2.8539e-02, -6.6491e-02],\n",
      "          [-1.7259e-02,  1.9573e-02, -1.1520e-02, -1.4134e-02, -5.1261e-02],\n",
      "          [-4.1505e-02, -4.7393e-02, -5.3418e-02,  2.5820e-02, -3.0123e-02],\n",
      "          [-4.2038e-02, -1.5300e-02, -2.7876e-02,  9.1607e-03, -7.4484e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.9699e-02, -4.2309e-03, -2.3213e-02, -5.2564e-02, -5.8726e-02],\n",
      "          [-5.6611e-02, -5.9198e-02, -3.9839e-02, -2.8795e-02, -3.8575e-02],\n",
      "          [-4.2585e-02, -4.0349e-03, -2.0420e-02, -5.5953e-02, -6.4966e-02],\n",
      "          [-5.1583e-02, -4.4496e-02, -4.0531e-02, -3.1861e-02, -3.5974e-02],\n",
      "          [-6.8224e-02, -2.3766e-02, -3.9714e-02, -1.8529e-02, -3.1314e-02]],\n",
      "\n",
      "         [[ 1.0467e-02,  3.2870e-02, -8.1763e-02, -9.7349e-05, -7.1126e-02],\n",
      "          [ 9.4846e-03,  7.7298e-03, -6.4817e-02,  3.0507e-03, -7.3575e-02],\n",
      "          [-3.8030e-02,  3.9610e-02, -5.0958e-02, -2.0464e-03, -1.0662e-01],\n",
      "          [ 1.2720e-02,  3.3958e-02, -5.5301e-02, -6.3209e-02, -1.0571e-01],\n",
      "          [-3.7868e-02,  1.4287e-02, -2.8784e-02, -1.6729e-02, -8.1242e-02]],\n",
      "\n",
      "         [[ 6.3912e-03, -1.4513e-02, -8.3240e-03,  5.2268e-02, -4.5449e-02],\n",
      "          [-1.3076e-02,  7.4935e-03, -2.4636e-02,  6.7753e-02, -3.7139e-02],\n",
      "          [-2.1166e-02,  4.1923e-02, -2.4366e-02,  2.3000e-02,  6.1130e-03],\n",
      "          [-3.7597e-03,  2.0330e-02,  1.1397e-02,  4.1921e-02, -3.9165e-02],\n",
      "          [ 9.8540e-03,  4.3632e-03,  1.0695e-02,  8.2503e-02, -4.3179e-03]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[ 2.7112e-03,  8.4226e-02,  1.5263e-02,  6.2632e-02, -3.1206e-02],\n",
      "          [-3.0876e-02,  4.4836e-02, -2.1415e-02,  2.0081e-02, -3.1932e-02],\n",
      "          [-6.2614e-02,  1.9165e-02, -2.3620e-02,  6.9623e-02,  1.2944e-02],\n",
      "          [-2.1417e-02,  3.3589e-02,  4.3133e-02,  8.5950e-02, -2.2663e-03],\n",
      "          [-3.0073e-02,  7.1906e-02,  3.0456e-02,  3.9771e-02,  9.3438e-03]],\n",
      "\n",
      "         [[ 8.7430e-03,  5.5023e-02,  4.8108e-02,  8.8783e-02,  5.2293e-03],\n",
      "          [-2.7724e-03,  8.3622e-02,  5.0487e-02,  9.3427e-02,  3.9012e-02],\n",
      "          [ 5.5306e-02,  3.9862e-02,  2.1236e-02,  4.0841e-02,  2.4933e-02],\n",
      "          [ 2.9913e-02,  5.6155e-03,  4.4360e-02,  9.5266e-02,  3.7734e-02],\n",
      "          [ 4.0886e-02,  6.1124e-02,  6.7466e-02,  7.4367e-02,  4.6480e-02]],\n",
      "\n",
      "         [[-3.1867e-02, -1.4884e-02, -1.2660e-02,  5.5965e-03, -5.7712e-02],\n",
      "          [-3.8316e-02, -3.4417e-02, -4.5491e-02, -1.2367e-02, -5.0505e-02],\n",
      "          [-6.9446e-02, -3.1533e-02, -4.4997e-02, -3.3171e-02, -2.2817e-02],\n",
      "          [-2.2616e-02,  6.0926e-04, -2.9248e-02, -4.6885e-02, -7.2060e-02],\n",
      "          [-4.0533e-02, -6.6247e-02, -5.5633e-02, -1.8275e-02, -1.5867e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-4.2058e-02, -4.7289e-02, -5.7160e-02, -5.4787e-02, -5.7071e-02],\n",
      "          [-5.1109e-02, -5.9953e-02,  1.9106e-04, -7.7175e-03, -5.8186e-02],\n",
      "          [-2.1377e-02, -3.7797e-02, -6.3803e-02, -5.1264e-02, -4.8575e-02],\n",
      "          [-6.6088e-02, -4.8681e-02, -4.4355e-02, -2.1049e-03, -6.0345e-02],\n",
      "          [-1.1277e-02, -6.6747e-02, -1.9475e-02, -6.0295e-02, -5.1394e-02]],\n",
      "\n",
      "         [[-1.5803e-02,  3.0300e-02,  3.9404e-02, -2.8384e-02,  3.4643e-02],\n",
      "          [ 6.4924e-02,  3.0593e-02,  5.2859e-02, -1.9287e-05,  4.6517e-02],\n",
      "          [ 1.5602e-02,  1.8584e-02,  1.9853e-02,  1.8568e-02,  1.2313e-02],\n",
      "          [ 5.4725e-02,  1.2834e-02,  1.7477e-02, -1.2685e-02,  6.4081e-02],\n",
      "          [ 6.1499e-02,  2.4619e-02, -1.5214e-02, -3.6694e-02,  6.5419e-02]],\n",
      "\n",
      "         [[-3.3135e-03, -2.7615e-02, -1.8903e-02, -6.8940e-02, -2.8833e-02],\n",
      "          [-1.0091e-02, -4.4831e-02,  3.6499e-02, -1.7327e-02,  2.1901e-02],\n",
      "          [ 1.7769e-03, -3.4173e-02, -3.6021e-02, -2.0665e-02,  8.0919e-03],\n",
      "          [-1.5019e-02, -8.4600e-02,  2.5744e-03, -1.8163e-02,  1.8957e-02],\n",
      "          [-1.8613e-02, -1.8553e-02, -1.2918e-02, -9.7483e-02,  3.5642e-02]]],\n",
      "\n",
      "\n",
      "        [[[-5.1332e-02, -1.0420e-02, -4.1750e-02, -6.4495e-03, -5.5658e-02],\n",
      "          [-4.2929e-02,  3.5196e-03, -6.7065e-02, -1.7700e-03, -4.4550e-02],\n",
      "          [-7.3394e-02,  3.0049e-02, -5.9954e-02,  2.3078e-02, -4.1341e-02],\n",
      "          [-5.1488e-02,  2.2565e-02, -2.0873e-02, -1.3633e-03, -7.3111e-03],\n",
      "          [-4.9918e-02,  3.9030e-02, -3.9775e-02,  5.9117e-02, -1.6541e-02]],\n",
      "\n",
      "         [[-9.4018e-02,  3.2873e-02, -3.8180e-02,  6.3045e-03, -6.5605e-02],\n",
      "          [-6.7976e-02,  1.3457e-02, -9.4874e-02, -7.4645e-03, -5.4318e-02],\n",
      "          [-7.2673e-02, -4.5028e-03, -5.2856e-02,  1.1964e-02, -7.3447e-02],\n",
      "          [-7.8211e-02,  1.6377e-02, -2.5674e-02,  3.6125e-02, -1.3805e-02],\n",
      "          [-6.1764e-02,  6.6337e-02, -8.2588e-02, -2.6139e-02, -3.7354e-02]],\n",
      "\n",
      "         [[ 6.2603e-02, -1.1661e-02,  1.6505e-02, -3.9795e-02,  5.9650e-02],\n",
      "          [ 7.1068e-02, -2.2164e-02,  1.2238e-02, -1.3662e-02,  7.6406e-02],\n",
      "          [ 3.8871e-02, -7.6306e-03,  1.3070e-02,  4.7528e-02,  2.6427e-02],\n",
      "          [ 3.0564e-02,  1.3193e-02,  2.3715e-02, -5.4375e-03,  5.0322e-02],\n",
      "          [ 4.8890e-02,  2.1201e-02,  4.9944e-02,  1.5165e-02,  7.0519e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.2449e-02,  7.9552e-02,  3.8345e-02,  7.0247e-02,  3.7313e-02],\n",
      "          [ 4.5537e-02,  6.5055e-02,  9.3011e-02,  4.2942e-02,  8.8208e-02],\n",
      "          [ 6.4002e-02,  6.7092e-02,  6.2954e-02,  3.0111e-02,  4.4910e-02],\n",
      "          [ 2.2539e-02,  3.1417e-02,  2.5346e-02,  7.0901e-02,  6.3986e-02],\n",
      "          [ 4.1983e-02,  6.3020e-02,  9.1096e-02,  2.6115e-02,  8.7414e-02]],\n",
      "\n",
      "         [[ 4.6376e-02, -5.7537e-02,  5.9094e-03, -1.4529e-03, -3.9403e-02],\n",
      "          [ 7.1323e-03, -5.0433e-02, -7.8385e-03, -4.4227e-02, -5.8720e-03],\n",
      "          [ 2.0454e-02, -2.6169e-02,  5.4280e-02,  1.3523e-02,  2.0418e-02],\n",
      "          [ 8.2353e-04,  4.5357e-03,  3.5848e-02,  2.8877e-03, -4.0977e-02],\n",
      "          [ 1.9158e-02, -2.8049e-02,  3.4081e-02, -8.4248e-03, -2.0391e-03]],\n",
      "\n",
      "         [[ 5.7169e-03,  2.1484e-02,  1.9422e-02, -6.2481e-03,  7.1488e-02],\n",
      "          [ 3.5894e-02, -2.4644e-02, -3.3338e-03,  3.6171e-02,  4.9141e-02],\n",
      "          [ 2.2473e-02,  6.1535e-02,  3.5280e-02,  3.5555e-02,  4.5982e-02],\n",
      "          [ 1.1283e-02,  5.3842e-02,  5.1216e-02,  1.6265e-02,  8.0918e-03],\n",
      "          [ 7.8737e-03,  2.6034e-02,  1.6782e-02,  4.7957e-03,  1.2876e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.8336e-02,  2.1685e-02,  1.1653e-02,  2.0368e-02,  2.0422e-02],\n",
      "          [-4.3672e-02,  1.8444e-03,  5.3774e-02,  2.0370e-02, -2.9142e-03],\n",
      "          [-2.0974e-02,  6.5432e-02, -1.6051e-03,  6.4731e-02, -1.0992e-02],\n",
      "          [-4.5953e-02,  3.9775e-02,  3.8515e-02, -1.2351e-02,  1.2711e-02],\n",
      "          [ 1.4346e-02,  3.1422e-02,  4.9881e-02, -7.0964e-03, -1.5175e-02]],\n",
      "\n",
      "         [[ 1.8025e-02,  7.3977e-03, -1.1245e-02,  9.3091e-04,  1.3911e-02],\n",
      "          [ 7.1698e-02, -2.5165e-02,  5.9457e-03, -1.6360e-02, -1.9232e-02],\n",
      "          [ 5.1018e-02, -4.7026e-02, -3.8990e-02,  2.3927e-02, -3.2428e-02],\n",
      "          [ 3.4620e-02,  3.6487e-03, -3.3507e-02,  4.8341e-03, -1.6390e-02],\n",
      "          [ 3.0436e-02,  4.3470e-02, -2.3589e-02, -9.1973e-03,  1.7083e-02]],\n",
      "\n",
      "         [[ 6.8587e-02,  1.5804e-02,  3.6501e-02, -2.9832e-04,  4.6969e-02],\n",
      "          [ 2.1863e-02, -4.1420e-02,  2.1257e-02, -2.6889e-02,  3.8601e-02],\n",
      "          [ 5.2572e-02, -1.6052e-02,  3.9523e-02, -1.3329e-02,  1.3713e-02],\n",
      "          [ 7.2166e-03,  1.5176e-02, -3.7092e-03, -1.0565e-03,  4.6853e-02],\n",
      "          [ 4.1898e-02,  6.5663e-03,  1.2591e-02, -3.1214e-03, -1.1887e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 5.7639e-03, -2.4133e-02,  2.5576e-02, -2.1418e-02,  2.2496e-02],\n",
      "          [ 1.9398e-02, -1.4809e-03,  2.6620e-02,  2.1392e-03,  2.6356e-02],\n",
      "          [-2.8487e-02,  5.6492e-03, -2.0029e-02,  2.6361e-02,  1.8189e-02],\n",
      "          [ 2.2653e-02,  1.1497e-03, -7.7426e-03,  2.9691e-02,  1.9382e-02],\n",
      "          [-2.1506e-02,  8.8334e-03,  2.5943e-02, -3.8361e-02,  1.5009e-02]],\n",
      "\n",
      "         [[ 5.0827e-02,  5.6030e-02,  1.8788e-02, -2.2105e-02,  3.2085e-02],\n",
      "          [ 9.6897e-02,  3.4925e-02, -6.4083e-03, -1.4950e-02,  6.0257e-02],\n",
      "          [ 1.0386e-01,  4.7632e-02, -3.2514e-02, -8.8075e-03,  9.2000e-03],\n",
      "          [ 1.0108e-01,  2.8144e-02, -4.2920e-02, -4.7797e-02,  2.0876e-02],\n",
      "          [ 8.2860e-02,  5.5110e-02,  1.2153e-02,  2.6529e-02,  3.9342e-02]],\n",
      "\n",
      "         [[ 2.1407e-02, -3.2946e-02, -2.1946e-04, -8.0297e-02,  2.8497e-02],\n",
      "          [ 3.9115e-02, -1.7029e-02,  2.9251e-02, -4.7446e-02,  6.6820e-03],\n",
      "          [ 3.7357e-02, -9.4201e-03, -1.9712e-02, -8.6478e-02,  3.0460e-02],\n",
      "          [ 2.6658e-02, -4.3681e-02,  1.3454e-02, -4.2923e-02,  5.2975e-02],\n",
      "          [ 4.4217e-02, -5.8899e-03, -2.8415e-02, -4.2318e-02,  3.4811e-02]]]],\n",
      "       device='cuda:0')), ('conv2.bias', tensor([-0.0199, -0.0194,  0.0602, -0.0310, -0.0024, -0.0732, -0.0610, -0.0002,\n",
      "        -0.0160,  0.0238, -0.0134, -0.0382, -0.0488,  0.0828,  0.0029, -0.0002,\n",
      "         0.0357, -0.0138, -0.0075,  0.0544, -0.0455, -0.0039,  0.0111,  0.0019,\n",
      "         0.0131,  0.0347, -0.0121,  0.0657,  0.0445,  0.0265, -0.0393, -0.0327],\n",
      "       device='cuda:0')), ('bn2.weight', tensor([1.0621, 1.0672, 1.0477, 1.0263, 1.1040, 0.9484, 1.0393, 0.9955, 1.0400,\n",
      "        0.9052, 1.0272, 1.0019, 0.9713, 0.9750, 1.0026, 1.0199, 0.8992, 0.9137,\n",
      "        1.0235, 0.9840, 1.0737, 0.9274, 0.9894, 0.9529, 1.0330, 0.9741, 0.9695,\n",
      "        0.9522, 0.9162, 1.0655, 0.9536, 0.9909], device='cuda:0')), ('bn2.bias', tensor([ 0.0884,  0.0587, -0.0088,  0.0105,  0.0549, -0.0188, -0.0628,  0.0151,\n",
      "         0.0444, -0.0254, -0.0023, -0.0442,  0.0372,  0.0694, -0.0729, -0.0764,\n",
      "         0.0292,  0.0498, -0.0476,  0.0242, -0.0399,  0.0675,  0.0346,  0.0995,\n",
      "        -0.0331, -0.0340, -0.0067,  0.0461, -0.0265,  0.0097,  0.0333, -0.0670],\n",
      "       device='cuda:0')), ('bn2.running_mean', tensor([1.1917e+00, 4.0645e-01, 5.8640e+00, 4.0833e-01, 1.4434e+00, 2.3514e-06,\n",
      "        2.8518e-02, 4.4366e+00, 1.8187e+00, 4.4487e+00, 2.4187e-29, 1.2004e+00,\n",
      "        2.1614e+00, 6.5431e+00, 1.9983e-40, 5.6052e-45, 2.6581e+00, 4.8272e+00,\n",
      "        5.2474e-05, 3.5207e+00, 6.5308e-04, 4.6037e+00, 1.5152e+00, 2.4739e+00,\n",
      "        9.5278e-01, 2.9873e+00, 1.2209e+00, 7.5974e+00, 1.2853e+00, 8.4217e-01,\n",
      "        1.3298e-08, 1.3149e+00], device='cuda:0')), ('bn2.running_var', tensor([6.3145e+00, 1.1073e+00, 1.9330e+01, 9.5916e-01, 7.6561e+00, 5.0860e-07,\n",
      "        2.6226e-02, 1.5329e+01, 7.4048e+00, 1.3812e+01, 1.7903e-30, 4.7213e+00,\n",
      "        9.6416e+00, 1.6420e+01, 4.2459e-43, 5.6052e-45, 1.2285e+01, 2.1130e+01,\n",
      "        1.0268e-05, 1.1776e+01, 1.6730e-04, 1.5202e+01, 4.6749e+00, 1.4436e+01,\n",
      "        5.5268e+00, 1.3874e+01, 6.2465e+00, 2.0732e+01, 5.8417e+00, 4.8123e+00,\n",
      "        2.6903e-09, 7.4341e+00], device='cuda:0')), ('bn2.num_batches_tracked', tensor(16396, device='cuda:0')), ('conv3.weight', tensor([[[[-3.6302e-02, -1.3467e-02, -9.1485e-02, -2.6177e-02,  3.4692e-02],\n",
      "          [-7.0722e-03, -9.1223e-03, -1.1514e-01, -1.5937e-02,  9.2018e-02],\n",
      "          [-4.5875e-03, -2.2008e-02, -8.2548e-02, -3.8091e-02,  3.1140e-02],\n",
      "          [-1.4551e-02,  1.6557e-02, -3.7974e-02, -3.0114e-02,  5.4188e-02],\n",
      "          [-3.1463e-03,  3.0024e-02, -1.1160e-01,  1.8142e-02,  7.8449e-02]],\n",
      "\n",
      "         [[-4.1651e-02, -2.9317e-02, -1.9158e-02,  3.6697e-02,  1.0447e-01],\n",
      "          [-1.6434e-02,  2.0094e-02, -2.5751e-02,  4.9306e-02,  7.8929e-02],\n",
      "          [-1.6555e-02, -1.5140e-02, -1.8791e-02,  2.4916e-02,  9.5849e-02],\n",
      "          [-4.9151e-02,  1.8401e-02, -2.7294e-02,  1.8660e-02,  1.0972e-01],\n",
      "          [-4.0028e-02,  3.2741e-02, -4.4617e-02,  4.3120e-02,  7.5149e-02]],\n",
      "\n",
      "         [[ 2.6380e-02,  6.3764e-02, -5.0732e-02, -9.0226e-02,  5.9032e-03],\n",
      "          [-1.6205e-02,  5.2766e-02, -5.8904e-02, -8.7872e-02,  6.2900e-03],\n",
      "          [ 3.8723e-03,  2.5429e-02, -5.9612e-02, -8.1699e-02,  1.9383e-02],\n",
      "          [-1.2486e-02,  3.5330e-03, -1.0460e-01, -8.8417e-02,  3.2234e-02],\n",
      "          [ 6.9771e-03, -2.4484e-03, -7.0463e-02, -7.6349e-02,  2.1538e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 1.4935e-02, -2.8018e-02, -1.7828e-02,  6.5177e-02,  6.9193e-02],\n",
      "          [ 6.6811e-03,  3.0922e-02, -2.0384e-02,  6.2386e-02,  9.7560e-02],\n",
      "          [-2.0528e-03, -3.1091e-02, -1.3327e-02,  1.9790e-02,  2.9180e-02],\n",
      "          [ 3.3592e-02,  2.7807e-02, -2.2921e-02,  3.3992e-02,  4.3663e-02],\n",
      "          [ 3.1974e-02, -3.1085e-02,  5.8406e-03,  6.1771e-02,  7.3701e-02]],\n",
      "\n",
      "         [[ 5.0365e-02, -3.4015e-02, -9.7160e-03, -1.4918e-03, -3.0279e-02],\n",
      "          [ 2.9376e-02,  4.4433e-03,  2.2235e-03,  3.7570e-02, -5.1650e-02],\n",
      "          [-1.8910e-02, -1.9583e-02, -2.3815e-02,  2.1818e-03, -1.4369e-02],\n",
      "          [-8.5710e-02, -1.5395e-02,  3.2769e-02,  2.2651e-02, -3.5860e-02],\n",
      "          [-2.5937e-04, -2.7817e-02, -1.1413e-02,  6.3189e-03, -2.7870e-02]],\n",
      "\n",
      "         [[ 1.6169e-02, -9.3296e-02, -4.9844e-02, -5.0099e-02,  1.3709e-02],\n",
      "          [ 1.2339e-02, -1.1504e-01, -1.8292e-02, -7.7078e-02, -8.1836e-03],\n",
      "          [ 2.7722e-02, -3.6408e-02, -1.1627e-05, -5.1280e-02,  1.7934e-02],\n",
      "          [ 3.3599e-02, -5.2037e-02,  1.3106e-02, -2.1164e-04,  2.9916e-02],\n",
      "          [-2.0715e-02, -8.1304e-02,  2.5447e-02, -1.0899e-02,  5.3078e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 7.5914e-02,  3.1470e-02, -8.1304e-03,  4.0792e-02,  1.3858e-02],\n",
      "          [ 1.0101e-01,  2.1000e-02,  1.8581e-03, -2.0086e-02,  1.7363e-03],\n",
      "          [ 8.1848e-02,  2.7595e-02,  2.0020e-02, -5.4838e-03, -5.3571e-02],\n",
      "          [ 2.3994e-02,  7.1845e-02,  2.2229e-02, -4.0199e-03, -3.5787e-02],\n",
      "          [ 5.5944e-02,  4.2885e-03, -1.2077e-02,  1.9071e-02, -1.7282e-02]],\n",
      "\n",
      "         [[ 1.0937e-01,  2.1475e-02, -6.3188e-02, -8.7209e-02, -3.0395e-02],\n",
      "          [ 6.7863e-02,  2.2959e-02, -2.8669e-02, -2.0058e-02, -1.4704e-02],\n",
      "          [ 7.6231e-02,  2.2211e-02, -5.1155e-02, -4.3023e-02, -2.1941e-02],\n",
      "          [ 6.1941e-02,  4.9719e-03, -3.8639e-02, -5.1843e-02, -4.3142e-02],\n",
      "          [ 7.2910e-02,  6.6849e-02, -8.6499e-03, -6.0562e-02, -4.2182e-02]],\n",
      "\n",
      "         [[ 2.3316e-02,  8.1127e-02,  2.8043e-02, -2.1519e-02,  3.8872e-02],\n",
      "          [ 2.8206e-02,  3.6655e-02, -2.3796e-02, -1.5990e-02, -1.7216e-03],\n",
      "          [ 7.9036e-03,  2.6445e-02,  7.8953e-03,  5.2735e-02,  5.2496e-03],\n",
      "          [ 2.9899e-02,  8.4943e-02,  9.6906e-05,  2.2297e-02,  1.9237e-02],\n",
      "          [ 1.1440e-02,  7.4735e-02,  2.4894e-03,  4.3258e-02,  4.1363e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 4.0318e-02,  2.9053e-02,  2.8416e-02, -2.6736e-02, -4.4871e-02],\n",
      "          [ 2.7098e-02, -9.0102e-03, -4.4316e-02, -2.6845e-02, -2.1420e-02],\n",
      "          [ 7.6343e-02, -4.7676e-03, -3.3771e-02, -4.3265e-02, -5.1604e-02],\n",
      "          [ 2.0216e-02, -7.4896e-02,  2.0380e-02, -9.7945e-03, -6.3838e-02],\n",
      "          [ 2.4449e-02, -2.4062e-02, -4.8779e-02, -2.1702e-02, -4.6689e-02]],\n",
      "\n",
      "         [[-2.6155e-03, -5.7188e-02, -1.1090e-02,  3.5730e-02, -2.0988e-02],\n",
      "          [-2.8870e-02,  2.1917e-03,  1.8243e-02,  7.2274e-02, -7.1419e-02],\n",
      "          [-3.8392e-02, -3.5289e-02, -6.3360e-04,  3.4197e-02, -1.0061e-02],\n",
      "          [-2.5521e-02, -1.3255e-02,  4.6584e-02,  4.0690e-02, -3.7585e-02],\n",
      "          [-5.6320e-02, -2.9148e-02,  1.3024e-02,  1.1087e-02, -4.6975e-02]],\n",
      "\n",
      "         [[ 5.0866e-03,  1.5040e-02, -9.0317e-02, -4.5236e-02,  9.8049e-02],\n",
      "          [ 9.0008e-03,  2.0078e-02, -5.5523e-03, -2.0436e-03,  5.6000e-02],\n",
      "          [ 3.4570e-02,  2.7832e-02, -4.5366e-02, -5.0012e-02,  8.7904e-02],\n",
      "          [-2.4713e-03,  1.3763e-02, -3.6608e-02, -6.0815e-02,  6.6355e-02],\n",
      "          [-4.4458e-03,  6.7920e-03, -7.1765e-02,  4.8513e-03,  8.0290e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.0523e-02, -5.3736e-02, -8.8457e-03,  8.4395e-02,  5.9525e-02],\n",
      "          [-2.9000e-02, -1.9740e-02, -1.1383e-02,  4.3733e-02,  9.8334e-02],\n",
      "          [-7.6669e-02, -2.1816e-02, -5.6653e-02,  6.1559e-02,  1.0736e-01],\n",
      "          [-4.5804e-02, -6.0071e-02, -4.8550e-02,  1.2764e-02,  9.7047e-02],\n",
      "          [-2.9606e-02, -2.4646e-02,  7.4093e-03,  1.3095e-01,  7.6575e-02]],\n",
      "\n",
      "         [[-9.0604e-02, -6.9559e-02, -1.4321e-02,  7.9954e-02, -2.4838e-02],\n",
      "          [-2.9913e-02, -5.0065e-02, -1.3749e-02,  4.4630e-02, -4.5834e-02],\n",
      "          [-6.0312e-02, -7.2809e-03, -2.2550e-02,  7.8629e-02, -5.4029e-02],\n",
      "          [-9.1810e-02, -3.0416e-02,  3.6317e-03,  3.2286e-02, -2.0743e-02],\n",
      "          [-9.3317e-02,  1.3884e-02, -3.2540e-02,  7.5693e-02,  3.4165e-02]],\n",
      "\n",
      "         [[ 3.3563e-02, -3.7322e-02, -3.8913e-02, -4.9461e-03,  2.4450e-02],\n",
      "          [-7.5149e-02, -4.9912e-02, -7.8201e-02, -1.9778e-02,  1.4389e-02],\n",
      "          [-3.8041e-02, -1.3432e-02, -8.0073e-02,  5.3060e-02,  8.1521e-02],\n",
      "          [ 1.5093e-02, -6.4309e-02,  1.5185e-02,  5.5278e-02,  2.5251e-02],\n",
      "          [-2.2885e-02, -4.4171e-04, -2.2655e-02,  5.4655e-02,  4.1775e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-3.3972e-02, -5.9251e-02, -3.6212e-02,  2.5026e-02,  5.4186e-02],\n",
      "          [-4.6709e-02, -2.7055e-02, -5.8569e-02,  4.2885e-02, -5.7681e-03],\n",
      "          [-5.8270e-02, -2.7047e-02, -1.5553e-02,  1.1592e-02,  4.4976e-02],\n",
      "          [-5.5655e-02, -2.3298e-02, -5.1335e-02,  4.8891e-02,  1.9452e-02],\n",
      "          [-7.3542e-02,  4.1732e-03, -4.8711e-02,  1.8343e-02,  3.7563e-02]],\n",
      "\n",
      "         [[-3.6993e-02,  1.5502e-02, -1.2742e-02, -4.2454e-04, -2.9199e-02],\n",
      "          [-1.1542e-02, -3.2289e-02, -1.9085e-02, -2.7997e-02,  5.6525e-03],\n",
      "          [-2.8896e-04, -3.3037e-02,  5.6147e-03, -4.5424e-02, -1.6058e-02],\n",
      "          [ 7.3453e-05, -1.7943e-02, -2.6818e-02, -6.6957e-02, -3.4557e-02],\n",
      "          [ 8.5434e-03,  1.1545e-02,  1.8833e-02, -7.4899e-03, -8.2024e-03]],\n",
      "\n",
      "         [[-2.5824e-02,  3.5645e-02,  1.7831e-02,  4.9346e-02,  1.1444e-01],\n",
      "          [-4.7981e-03,  2.6927e-02, -9.7482e-02,  3.5341e-02,  9.3194e-02],\n",
      "          [-2.6812e-02,  1.3367e-02, -3.6809e-02,  5.8862e-02,  9.0354e-02],\n",
      "          [-2.9344e-02,  8.1253e-03, -2.0622e-02,  3.1434e-02,  1.1157e-01],\n",
      "          [ 2.1768e-02,  6.6453e-02, -6.6219e-02,  5.7930e-02,  8.3376e-02]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[-1.0713e-02, -4.6523e-02, -4.0456e-02, -4.8015e-02, -3.2307e-02],\n",
      "          [-1.2048e-02, -2.3557e-03, -6.9009e-02, -8.6110e-02,  6.8859e-03],\n",
      "          [ 3.7464e-04, -5.6282e-03, -7.7172e-02, -3.0294e-02, -2.0307e-02],\n",
      "          [-1.2731e-02, -3.2862e-03, -7.4992e-02, -8.4052e-02,  1.7355e-03],\n",
      "          [ 2.9498e-02,  2.6120e-02, -2.3540e-02, -5.8421e-02,  2.3427e-02]],\n",
      "\n",
      "         [[ 5.3601e-02,  4.5013e-02, -9.6076e-03, -6.8767e-03,  1.4056e-02],\n",
      "          [-3.0914e-02,  7.2251e-02,  1.8834e-02, -6.1606e-03, -1.3976e-02],\n",
      "          [ 5.0433e-02,  2.1520e-02,  2.4682e-02,  1.5910e-02,  5.7397e-02],\n",
      "          [ 2.3078e-02,  8.5119e-02, -1.4782e-02, -1.1932e-02,  6.2172e-02],\n",
      "          [ 4.0013e-02,  4.3476e-02,  5.5728e-03, -3.5378e-02,  1.5779e-02]],\n",
      "\n",
      "         [[ 7.6407e-03,  1.9948e-02, -3.3077e-02, -3.8911e-02, -3.0619e-02],\n",
      "          [ 5.5131e-02,  7.1949e-02, -1.7433e-02, -2.5109e-02, -7.6505e-02],\n",
      "          [-6.8600e-03,  5.5647e-02, -4.2667e-02, -4.0200e-02, -8.1894e-02],\n",
      "          [ 5.4789e-02,  6.2323e-02, -7.8974e-02, -3.1111e-02, -6.1843e-02],\n",
      "          [-2.1328e-02,  5.1364e-02, -5.9110e-02, -5.4728e-02, -5.7346e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.3700e-02, -7.8496e-03,  1.9074e-02, -1.3429e-02,  2.8110e-02],\n",
      "          [ 6.3196e-02,  3.8926e-02,  5.3234e-02, -1.8518e-02, -1.4942e-02],\n",
      "          [ 3.6548e-02,  2.4641e-02, -7.0256e-04,  4.3047e-03, -1.9557e-02],\n",
      "          [ 2.9787e-02,  2.1804e-02,  3.5130e-02, -3.7951e-03,  1.4811e-03],\n",
      "          [ 1.5719e-02,  2.2797e-02,  5.1184e-02, -1.9053e-02, -1.1103e-02]],\n",
      "\n",
      "         [[-1.1356e-02, -2.0792e-02,  4.9450e-03, -2.2323e-02, -2.8150e-02],\n",
      "          [ 2.1164e-02, -1.9945e-02,  8.1704e-02,  1.7696e-02,  2.8057e-02],\n",
      "          [-1.0362e-02, -4.1458e-02,  7.0067e-02, -3.0888e-02, -2.7388e-02],\n",
      "          [ 1.2283e-02, -4.9715e-02, -1.1230e-02, -9.9260e-03, -2.9089e-02],\n",
      "          [ 5.6257e-02, -1.6257e-02, -7.5811e-03,  9.8582e-03,  1.6377e-02]],\n",
      "\n",
      "         [[-5.3122e-02, -3.9973e-02, -4.0435e-02, -3.1117e-02, -1.4278e-02],\n",
      "          [-5.0437e-02, -1.5493e-02,  8.0877e-03, -9.0784e-02,  2.9941e-02],\n",
      "          [-6.1818e-02, -2.0614e-02,  1.4050e-02, -2.3964e-02,  2.4433e-02],\n",
      "          [-3.4684e-02, -4.0291e-02,  1.9849e-02, -3.9858e-02,  4.1268e-02],\n",
      "          [-7.8100e-02, -5.4322e-02, -4.8392e-02, -5.1302e-02,  5.0927e-02]]],\n",
      "\n",
      "\n",
      "        [[[ 3.5174e-02,  1.0130e-02,  5.3672e-02,  1.0030e-03,  5.1360e-02],\n",
      "          [ 3.3529e-02, -4.1501e-02,  8.7032e-02,  1.1468e-02, -1.1634e-02],\n",
      "          [ 5.5978e-02, -3.8337e-03,  9.1162e-02,  9.0928e-03, -1.7391e-02],\n",
      "          [ 4.6894e-02, -2.8607e-02,  5.0389e-02,  3.6697e-02, -7.6472e-03],\n",
      "          [ 2.6042e-02,  8.5919e-03,  1.1905e-01,  4.5221e-02,  1.6229e-02]],\n",
      "\n",
      "         [[ 5.8736e-03,  4.8867e-02,  5.9792e-02,  1.4827e-02, -7.5306e-03],\n",
      "          [-7.6263e-03,  6.9509e-02,  8.7579e-02,  1.1368e-02,  3.6676e-02],\n",
      "          [-1.9555e-02,  8.7547e-02,  5.2589e-02,  2.4813e-02, -3.0689e-02],\n",
      "          [-3.5442e-03,  5.3304e-02,  6.5877e-02,  4.7003e-02, -2.3353e-02],\n",
      "          [-1.3956e-02,  5.9879e-02,  8.3806e-02,  3.1066e-02, -1.8099e-02]],\n",
      "\n",
      "         [[-1.6608e-02, -1.0701e-02,  5.2080e-02, -4.0649e-03, -5.5122e-03],\n",
      "          [-9.1984e-02, -2.1354e-02,  2.2142e-02, -1.1486e-02,  2.0904e-02],\n",
      "          [-6.4567e-02, -2.7588e-02,  8.3239e-03,  4.8931e-02, -2.0188e-02],\n",
      "          [-3.6051e-02, -6.7184e-02,  5.5218e-02,  1.5195e-02,  2.5062e-02],\n",
      "          [-5.4676e-04, -2.6372e-02, -7.0800e-03,  1.6039e-02,  2.3631e-03]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 3.1613e-02,  1.1878e-02,  8.3367e-02,  4.8869e-02,  9.8070e-02],\n",
      "          [ 4.4857e-02,  1.1942e-02,  5.3042e-02,  2.3364e-02,  8.4214e-02],\n",
      "          [ 8.8017e-03,  5.3919e-02,  6.8079e-02,  4.8639e-02,  4.3998e-02],\n",
      "          [-1.9832e-02,  5.1476e-02,  1.1183e-01, -9.1974e-03,  7.4124e-02],\n",
      "          [ 1.4929e-02,  1.8917e-02,  6.1413e-02,  4.5791e-02,  6.1889e-02]],\n",
      "\n",
      "         [[-1.0079e-02, -8.5080e-04,  6.4380e-02,  9.2842e-02, -1.4151e-02],\n",
      "          [-5.1878e-03, -3.4236e-02,  4.4144e-02,  3.0323e-02,  2.1432e-02],\n",
      "          [-9.8280e-03, -2.3749e-02,  2.6883e-02, -8.4676e-03,  2.0625e-02],\n",
      "          [-3.2153e-02, -3.0452e-02,  1.0383e-02, -2.3100e-02,  1.6327e-02],\n",
      "          [-1.9216e-02, -6.0159e-03,  4.9985e-02, -6.9410e-03, -3.1361e-02]],\n",
      "\n",
      "         [[ 5.3015e-02,  3.5495e-02,  2.2784e-02, -1.0587e-02, -8.1926e-03],\n",
      "          [ 6.2704e-02,  2.2950e-02,  3.6527e-02,  1.8868e-02,  6.7081e-02],\n",
      "          [ 5.6986e-02,  5.0236e-02,  1.2073e-02,  3.7162e-02,  4.6610e-02],\n",
      "          [ 7.3979e-03,  5.4395e-02, -2.3231e-02,  3.9394e-02, -2.4039e-03],\n",
      "          [ 9.9848e-03,  1.8505e-02,  1.8696e-03,  4.7012e-02,  2.1319e-02]]],\n",
      "\n",
      "\n",
      "        [[[-3.9963e-02,  6.2436e-02,  5.3750e-02, -1.6876e-03,  1.1611e-02],\n",
      "          [ 2.3212e-02,  8.8774e-02,  5.1362e-02,  1.5002e-02, -3.5741e-02],\n",
      "          [-6.5539e-02,  5.1668e-02,  7.5237e-02, -1.6151e-02, -4.0827e-02],\n",
      "          [-7.2318e-02,  8.9698e-02,  8.1066e-02,  9.5224e-03, -4.8295e-02],\n",
      "          [-2.8457e-02,  2.5208e-02,  6.8401e-02, -3.0757e-02, -4.6679e-02]],\n",
      "\n",
      "         [[ 9.4003e-02,  1.0186e-01,  1.5234e-02, -4.3336e-02, -4.2133e-02],\n",
      "          [ 2.6577e-02,  1.0444e-01, -7.1203e-02, -5.6270e-02, -7.2741e-02],\n",
      "          [-2.4423e-02,  6.3753e-02,  4.3498e-02, -2.4328e-02, -5.5549e-02],\n",
      "          [ 5.3575e-02,  7.1871e-02,  1.9899e-02, -2.6278e-02, -6.4334e-02],\n",
      "          [ 1.6962e-02,  9.0650e-02,  7.9824e-03,  5.7756e-03, -9.6116e-02]],\n",
      "\n",
      "         [[-4.8968e-02, -3.2579e-02,  3.9270e-02, -7.7538e-04,  3.6398e-03],\n",
      "          [-9.5845e-02,  2.2921e-02,  9.6204e-02,  4.3194e-02, -6.3638e-03],\n",
      "          [-6.6082e-02, -1.3745e-02,  6.1816e-02,  5.3975e-02, -3.3516e-03],\n",
      "          [-1.1792e-01,  1.9150e-02,  4.5052e-02,  3.7484e-02, -7.1476e-02],\n",
      "          [-9.9074e-02, -3.7098e-02,  2.7203e-02,  4.3914e-02, -3.1671e-02]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-2.4701e-02,  8.0636e-02,  4.0586e-03, -5.5340e-02, -1.2001e-02],\n",
      "          [-3.7840e-03,  1.6914e-02, -2.7412e-02, -2.0952e-02, -5.8928e-02],\n",
      "          [-1.0684e-02,  3.4378e-02, -3.3985e-03, -2.2265e-03, -3.5359e-02],\n",
      "          [ 1.8588e-03,  4.0256e-02, -1.7184e-02, -6.3310e-02, -7.2033e-02],\n",
      "          [ 7.3190e-03,  4.0037e-02,  1.7419e-02, -2.8098e-02, -7.6458e-02]],\n",
      "\n",
      "         [[ 7.4155e-03,  6.1257e-03,  4.8282e-02, -7.7183e-02,  1.0281e-03],\n",
      "          [ 5.4239e-04, -1.9164e-02, -2.5770e-02, -2.2562e-02,  3.1612e-02],\n",
      "          [ 2.5054e-02, -5.4371e-02, -2.6942e-03, -6.9292e-03,  3.5229e-02],\n",
      "          [-1.7915e-02, -1.9211e-02, -2.8078e-02,  2.4556e-02,  3.7217e-02],\n",
      "          [-7.2763e-03, -4.8240e-02, -5.0977e-02,  2.4027e-02,  1.3245e-02]],\n",
      "\n",
      "         [[-4.3800e-02,  1.8844e-02,  4.1024e-02, -2.9595e-02, -1.5687e-02],\n",
      "          [ 4.6834e-03,  7.4751e-04,  2.0653e-02, -3.4424e-02, -3.5716e-03],\n",
      "          [ 2.0236e-02, -6.0304e-03,  3.1582e-02, -1.1465e-02, -2.3922e-03],\n",
      "          [-2.5698e-02, -4.6845e-02, -1.7709e-02, -5.5047e-02,  2.9259e-02],\n",
      "          [-3.8286e-02,  1.0852e-02, -1.2609e-02, -3.6614e-02,  9.2361e-03]]]],\n",
      "       device='cuda:0')), ('conv3.bias', tensor([-0.0430, -0.0138, -0.0476, -0.0912, -0.0141,  0.0011,  0.0463, -0.0396,\n",
      "         0.0034, -0.0457, -0.0242,  0.0028, -0.0279, -0.0870, -0.0329,  0.0084,\n",
      "        -0.0773, -0.0426, -0.0836, -0.0519,  0.0031, -0.0474,  0.0405, -0.0468,\n",
      "        -0.0145,  0.0131, -0.0738,  0.0050, -0.0035, -0.0177, -0.0106, -0.0365,\n",
      "        -0.0856, -0.0277, -0.0252, -0.0036, -0.0116, -0.0577, -0.0363, -0.0282,\n",
      "        -0.0853, -0.0373,  0.0023,  0.0083, -0.0076, -0.0664, -0.0720, -0.0384,\n",
      "        -0.0309,  0.0149, -0.0773, -0.0868, -0.0637, -0.0352, -0.0126,  0.0003,\n",
      "         0.0086,  0.0143, -0.0286,  0.0006, -0.0418,  0.1160, -0.0489,  0.0605],\n",
      "       device='cuda:0')), ('bn3.weight', tensor([0.9785, 0.9938, 0.9805, 1.0743, 0.9606, 1.0396, 0.9549, 1.0239, 0.9374,\n",
      "        0.9544, 1.0736, 0.9643, 1.0468, 1.0185, 0.9621, 1.0300, 0.9642, 0.9418,\n",
      "        1.0754, 1.0693, 0.9789, 1.0876, 0.9564, 0.9466, 1.0493, 0.9019, 1.0504,\n",
      "        0.9355, 1.0633, 0.9343, 1.1067, 1.0048, 1.0314, 0.9692, 1.0228, 0.9835,\n",
      "        1.0388, 0.9918, 0.9369, 0.9452, 0.9892, 1.0498, 1.0043, 1.0129, 1.0114,\n",
      "        0.9671, 1.0244, 0.9463, 0.9702, 0.9850, 0.9968, 0.9765, 1.0045, 1.0383,\n",
      "        0.9827, 0.9784, 0.9966, 0.9839, 1.0409, 1.0447, 1.0298, 1.0011, 0.9861,\n",
      "        1.0066], device='cuda:0')), ('bn3.bias', tensor([-0.0449, -0.0497, -0.0601, -0.0597, -0.0491, -0.0485, -0.0482, -0.0467,\n",
      "        -0.0628, -0.0461, -0.0463, -0.0509, -0.0621, -0.0531, -0.0593, -0.0608,\n",
      "        -0.0581, -0.0581, -0.0488, -0.0602, -0.0511, -0.0460, -0.0612, -0.0611,\n",
      "        -0.0649, -0.0619, -0.0589, -0.0474, -0.0628, -0.0611, -0.0476, -0.0461,\n",
      "        -0.0600, -0.0650, -0.0617, -0.0485, -0.0590, -0.0465, -0.0458, -0.0577,\n",
      "        -0.0476, -0.0476, -0.0475, -0.0533, -0.0650, -0.0486, -0.0607, -0.0606,\n",
      "        -0.0601, -0.0591, -0.0505, -0.0626, -0.0583, -0.0590, -0.0611, -0.0576,\n",
      "        -0.0591, -0.0491, -0.0594, -0.0601, -0.0484, -0.0605, -0.0611, -0.0497],\n",
      "       device='cuda:0')), ('bn3.running_mean', tensor([1.8795, 1.5453, 1.8439, 1.6400, 1.9748, 1.8075, 2.1532, 2.1096, 1.4199,\n",
      "        2.0116, 2.0474, 2.1352, 1.8224, 1.4109, 1.8068, 1.7882, 1.7018, 1.6433,\n",
      "        1.8922, 1.6874, 2.0707, 1.9604, 1.5380, 1.3507, 2.0274, 1.6482, 1.8180,\n",
      "        1.4482, 1.3168, 1.6209, 2.1643, 1.6197, 1.8596, 2.0725, 1.5878, 1.7992,\n",
      "        2.0333, 2.0561, 1.8301, 1.6731, 1.7836, 1.9951, 1.7772, 1.9119, 1.8662,\n",
      "        0.9958, 1.9587, 1.6671, 1.9387, 2.1189, 1.2538, 1.9665, 1.9260, 1.9522,\n",
      "        2.1178, 2.0695, 1.8341, 2.0356, 1.9500, 1.7653, 2.1484, 1.6652, 1.9017,\n",
      "        2.0092], device='cuda:0')), ('bn3.running_var', tensor([ 9.7313,  4.7257,  8.9681,  7.3697,  7.7171,  9.0697, 10.7708, 14.0328,\n",
      "         3.6254, 12.5202, 14.8260, 11.8551,  7.7568,  4.3094,  7.4009,  7.6202,\n",
      "         9.4455, 12.5030,  9.8809,  6.9189,  9.6228, 11.2214,  3.8637,  6.7970,\n",
      "        10.1861,  5.7667, 10.5218,  5.2618,  4.6313,  6.5669, 13.7429,  7.7947,\n",
      "         9.0249,  6.8507,  6.0755,  7.1717, 10.8326, 14.0276, 12.6200,  8.1024,\n",
      "         7.1180,  9.8928,  9.0158,  7.4329, 12.3057,  2.8870, 12.1081, 13.0494,\n",
      "         8.8851,  8.6734,  4.6890, 15.8735, 12.3562,  8.7390, 15.2136, 14.1713,\n",
      "         8.9521,  7.6326, 12.0095,  7.6813, 12.2100,  5.4920, 13.6143,  9.0962],\n",
      "       device='cuda:0')), ('bn3.num_batches_tracked', tensor(16396, device='cuda:0')), ('fc.weight', tensor([[-0.0204, -0.0215, -0.0195,  ..., -0.0227, -0.0155, -0.0305],\n",
      "        [ 0.0061,  0.0065, -0.0078,  ..., -0.0062,  0.0063,  0.0058]],\n",
      "       device='cuda:0')), ('fc.bias', tensor([0.0358, 0.0063], device='cuda:0')), ('fc2.weight', tensor([[-0.1526,  0.3917]], device='cuda:0')), ('fc2.bias', tensor([-3.7352], device='cuda:0'))])\n"
     ]
    }
   ],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    model_transfer.eval() #set model into evaluation/testing mode. It turns of drop off layer\n",
    "    with torch.no_grad():\n",
    "        #Iterating over test data\n",
    "        for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            output = model(data).to(device)\n",
    "            # calculate the loss\n",
    "            loss = criterion(output, target)\n",
    "            # update average test loss \n",
    "            test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "            # convert output probabilities to predicted class\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            # compare predictions to \n",
    "            correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "            total += data.size(0)\n",
    "\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))\n",
    "\n",
    "# call test function    \n",
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)\n",
    "\n",
    "\n",
    "#Obtain one batch of test images\n",
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.__next__()\n",
    "images.numpy\n",
    "\n",
    "#Move model inputs to cuda, if GPU available\n",
    "if use_cuda:\n",
    "    images = images.cuda()\n",
    "\n",
    "#Get sample outputs\n",
    "output= model_transfer(images)\n",
    "\n",
    "#Convert output probabilities to predicted class\n",
    "_,preds_tensor = torch.max(output,1)\n",
    "preds = np.squeeze(preds_tensor.numpy()) if not use_cuda else np.squeeze(preds_tensor.cpu().numpy())\n",
    "\n",
    "print(model_transfer.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1af735",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:36:04.754442Z",
     "iopub.status.busy": "2025-10-15T17:36:04.754108Z",
     "iopub.status.idle": "2025-10-15T17:36:46.426832Z",
     "shell.execute_reply": "2025-10-15T17:36:46.425750Z"
    },
    "papermill": {
     "duration": 41.685556,
     "end_time": "2025-10-15T17:36:46.433958",
     "exception": false,
     "start_time": "2025-10-15T17:36:04.748402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0., 327.],\n",
      "        [  0., 845.]])\n"
     ]
    }
   ],
   "source": [
    "nb_classes = 2\n",
    "\n",
    "confusion_matrix = torch.zeros(nb_classes, nb_classes)\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, classes) in enumerate(loaders_transfer['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        classes = classes.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        for t, p in zip(classes.view(-1), preds.view(-1)):\n",
    "                confusion_matrix[t.long(), p.long()] += 1\n",
    "\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7582e432",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-15T17:36:46.444890Z",
     "iopub.status.busy": "2025-10-15T17:36:46.444630Z",
     "iopub.status.idle": "2025-10-15T17:36:46.495528Z",
     "shell.execute_reply": "2025-10-15T17:36:46.494498Z"
    },
    "papermill": {
     "duration": 0.058445,
     "end_time": "2025-10-15T17:36:46.497385",
     "exception": false,
     "start_time": "2025-10-15T17:36:46.438940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0.]], device='cuda:0', grad_fn=<CatBackward0>) tensor([0], device='cuda:0') ['normal']\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )])\n",
    "# /kaggle/input/human-non-human-classical-quantum-dataset/humannonhuman-conv/humannonhuman-conv/humans/AJ_Lamas_0001_conv.jpg\n",
    "image_path = \"/kaggle/input/chest-x-ray-classical-and-quantum-dataset/chestxray-conv/chestxray-conv/PNEUMONIA/person1000_bacteria_2931_conv.jpg\"\n",
    "img = Image.open(image_path)\n",
    "img = img.convert('RGB')\n",
    "batch_t = torch.unsqueeze(transform(img), 0)\n",
    "device = torch.device(\"cuda\")\n",
    "batch_t = batch_t.to(device)\n",
    "\n",
    "model.eval()\n",
    "outputs = model(batch_t)\n",
    "_, predicted = torch.max(outputs, 1)\n",
    "title = [['normal','pneumonia'][x] for x in predicted]\n",
    "#prob = torch.nn.functional.softmax(1, dim=1)[0] * 100\n",
    "print(outputs,predicted,title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0d1988",
   "metadata": {
    "papermill": {
     "duration": 0.004836,
     "end_time": "2025-10-15T17:36:46.507351",
     "exception": false,
     "start_time": "2025-10-15T17:36:46.502515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 2902458,
     "sourceId": 5002696,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 2909342,
     "sourceId": 5013843,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3875642,
     "sourceId": 6728413,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3931951,
     "sourceId": 6839494,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30388,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1598.068142,
   "end_time": "2025-10-15T17:36:49.117771",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-15T17:10:11.049629",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
